{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Home path not equal to work path, changing!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Project/Local_Project/InceptionTimeV2.8/CODE/demo\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "__file__ = %pwd\n",
    "sys.path.append(os.path.dirname(__file__))\n",
    "from Package import *\n",
    "logger = logging.getLogger()\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.WARNING)\n",
    "print(__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_datasets = datasets[:10]\n",
    "train_epoch = 1000\n",
    "attack_epoch1 = 1000\n",
    "attack_epoch2 = 100\n",
    "override = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_path = ''\n",
    "for i in sub_datasets:\n",
    "    trainer = Trainer(\n",
    "        i, \n",
    "        batch_size=256, \n",
    "        epoch = train_epoch, \n",
    "        override=override,\n",
    "        continue_train = False,\n",
    "        )\n",
    "    method_path = trainer.method_path\n",
    "    # trainer.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_metrics_train(mode=\"train\", method=method_path, datasets=sub_datasets)\n",
    "concat_metrics_train(mode=\"test\", method=method_path, datasets=sub_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=[]\n",
    "for k in sys.modules.keys():\n",
    "    if \"CODE.attack.mix\" in k:\n",
    "        print(k)\n",
    "        keys.append(k)\n",
    "for k in keys:\n",
    "    del sys.modules[k]\n",
    "\n",
    "from CODE.attack.mix import Mix\n",
    "model_class = Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_series = [\n",
    "    {\n",
    "        'epoch': attack_epoch1,\n",
    "        'swap': True,\n",
    "        'kl_loss': True,\n",
    "        'CW': True,\n",
    "        'sign_only': False,\n",
    "        'alpha': 0.02\n",
    "    },\n",
    "    {\n",
    "        'epoch': attack_epoch1,\n",
    "        'swap': False,\n",
    "        'kl_loss': False,\n",
    "        'CW': False,\n",
    "        'sign_only': False,\n",
    "        'alpha': 0.02\n",
    "    },\n",
    "    {\n",
    "        'epoch': 1,\n",
    "        'swap': False,\n",
    "        'kl_loss': False,\n",
    "        'CW': False,\n",
    "        'sign_only': True,\n",
    "        'alpha': 0.1\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_parameter = [\n",
    "    \"swap\",\n",
    "    \"kl_loss\",\n",
    "    \"CW\",\n",
    "    \"sign_only\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n",
      "WARNING:root:adeversarial_training: True\n"
     ]
    }
   ],
   "source": [
    "attack_method_path_series = []\n",
    "\n",
    "for i in sub_datasets:\n",
    "    for j in attack_series:\n",
    "        # pprint(j)\n",
    "        attacker = model_class(\n",
    "            dataset=i,\n",
    "            batch_size=128, \n",
    "            epoch=j['epoch'], \n",
    "            swap=j['swap'],\n",
    "            kl_loss=j['kl_loss'],\n",
    "            CW=j['CW'],\n",
    "            train_method_path = method_path,\n",
    "            adeversarial_training = True,\n",
    "            sign_only=j['sign_only'],\n",
    "            alpha=j['alpha'],\n",
    "            path_parameter=path_parameter\n",
    "            )\n",
    "        attack_method_path_series.append(attacker.attack_method_path) if not attacker.attack_method_path in attack_method_path_series else None\n",
    "        # attacker.perturb_all(\n",
    "        #     to_device=False,\n",
    "        #     override=override,\n",
    "        # )\n",
    "        # attacker.build_adeversarial_training_data()\n",
    "        # pprint(attacker.path_parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swap=True_kl_loss=True_CW=True_sign_only=False',\n",
       " 'swap=False_kl_loss=False_CW=False_sign_only=False',\n",
       " 'swap=False_kl_loss=False_CW=False_sign_only=True']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_method_path_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00301: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00352: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00403: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00454: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00341: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00629: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00933: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00206: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00257: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00308: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00359: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00162: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00213: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00264: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00479: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00180: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00454: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00505: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00556: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00082: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00133: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00184: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00235: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00118: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00169: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00220: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00271: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00151: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00202: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00253: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00304: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00082: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00133: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00184: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00235: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00252: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00303: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00354: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00405: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00485: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00586: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00685: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00736: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00157: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00208: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00259: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00310: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00245: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00296: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00347: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00398: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00159: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00210: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00261: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00312: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00116: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00167: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00218: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00269: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00115: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00166: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00217: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00268: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00201: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00252: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00303: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00354: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00060: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00111: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00162: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00213: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00067: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00118: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00169: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00220: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00278: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00329: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00380: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00431: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00324: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00483: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00590: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00713: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00267: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00318: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00369: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00420: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00217: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00268: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00319: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00370: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00204: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00255: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00306: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00357: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00124: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00175: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00226: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00277: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00066: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00117: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00168: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00219: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00207: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00258: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00309: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00360: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00061: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00112: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00163: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00214: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00118: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00169: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00220: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00271: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "train_method_path_series = []\n",
    "method_path = ''\n",
    "for j in attack_method_path_series:\n",
    "    for i in sub_datasets:\n",
    "        trainer = Trainer(\n",
    "            i, \n",
    "            batch_size=256,\n",
    "            epoch = train_epoch,\n",
    "            override=override,\n",
    "            continue_train = False,\n",
    "            adeversarial_training = True,\n",
    "            adeversarial_path=j,\n",
    "            adeversarial_resume=False\n",
    "            )\n",
    "        method_path = trainer.method_path\n",
    "        train_method_path_series.append(method_path) if not method_path in train_method_path_series else None\n",
    "        trainer.train_and_evaluate()\n",
    "    concat_metrics_train(mode=\"train\", method=method_path, datasets=sub_datasets)\n",
    "    concat_metrics_train(mode=\"test\", method=method_path, datasets=sub_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_series = [\n",
    "    {\n",
    "        'epoch': attack_epoch2,\n",
    "        'swap': True,\n",
    "        'kl_loss': True,\n",
    "        'CW': True,\n",
    "        'sign_only': False,\n",
    "        'alpha': 0.02\n",
    "    },\n",
    "    {\n",
    "        'epoch': attack_epoch2,\n",
    "        'swap': False,\n",
    "        'kl_loss': False,\n",
    "        'CW': False,\n",
    "        'sign_only': False,\n",
    "        'alpha': 0.02\n",
    "    },\n",
    "    {\n",
    "        'epoch': 1,\n",
    "        'swap': False,\n",
    "        'kl_loss': False,\n",
    "        'CW': False,\n",
    "        'sign_only': True,\n",
    "        'alpha': 0.1\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for j in attack_series:\n",
    "    for k in train_method_path_series:\n",
    "        for i in sub_datasets:\n",
    "            attacker = model_class(\n",
    "                dataset=i,\n",
    "                batch_size=128, \n",
    "                epoch=j['epoch'], \n",
    "                swap=j['swap'],\n",
    "                kl_loss=j['kl_loss'],\n",
    "                CW=j['CW'],\n",
    "                train_method_path = k,\n",
    "                adeversarial_training = False,\n",
    "                sign_only=j['sign_only'],\n",
    "                alpha=j['alpha'],\n",
    "                path_parameter=path_parameter\n",
    "                )\n",
    "            attacker.perturb_all(\n",
    "                to_device=True,\n",
    "                override=override,\n",
    "            )\n",
    "        concat_metrics_attack(\n",
    "            method = os.path.join(k, attacker.attack_method_path),datasets=sub_datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
